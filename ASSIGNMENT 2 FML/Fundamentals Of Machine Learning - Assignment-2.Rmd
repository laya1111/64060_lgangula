---
title: "Fundamentals Of Machine Learning- Assignment 2"
author: "LAYA SREE GANGULA"
date: "2022-10-04"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(class)
library(dplyr)
library(caret)
library(tinytex)
data_1 <- read.csv("C://Users//heere//Downloads//UniversalBank (2).csv")

#Elimination the ID AND ZIP CODE Columns
data_1$ID<-NULL
data_1$ZIP.Code<-NULL
View(data_1)

#converting to factor variable
data_1$Personal.Loan=as.factor(data_1$Personal.Loan)

#Checking if there is any null variables
head(is.na(data_1))

#Transforming Education to character
data_1$Education=as.character(data_1$Education)

#Creating dummy  variables
Education_1 <- ifelse(data_1$Education==1 ,1,0)

Education_2 <- ifelse(data_1$Education==2 ,1,0)

Education_3 <- ifelse(data_1$Education==3 ,1,0)




data_2<-data.frame(Age=data_1$Age,Experience=data_1$Experience,Income=data_1$Income,Family=data_1$Family,CCAvg=data_1$CCAvg, Education_1=Education_1,Education_2=Education_2,Education_3=Education_3,Personal.Loan=data_1$Personal.Loan,Mortgage=data_1$Mortgage,Securities.Account=data_1$Securities.Account,CD.Account=data_1$CD.Account,Online=data_1$Online,CreditCard=data_1$CreditCard)


#defining testdata
test_1<-data.frame(Age=40,Experience=10,Income=84,Family=2,CCAvg=2,Education_1=0,Education_2=1,Education_3=0,Mortgage=0,Securities.Account=0,CD.Account=0,Online=1,CreditCard=1)

#splitting data to 60:40
set.seed(250)
temp<- createDataPartition(data_2$Personal.Loan,p=.6,list=FALSE,times=1)
train_1 <- data_2[temp, ]
valid_1<- data_2[-temp, ]

#Normalization
Norm_Model=preProcess(test_1[,-(6:9)],method=c("center","scale"))
train_1_Norm =predict(Norm_Model,train_1)
valid_1_Norm =predict(Norm_Model,valid_1)
test_1_Norm =predict(Norm_Model,test_1)

View(train_1_Norm)

#running knn algorithm

predict_train<-train_1_Norm[,-9]
train_sample<-train_1_Norm[,9]
predict_valid<-valid_1_Norm[,-9]
valid_sample<-valid_1_Norm[,9]

predict<-knn(predict_train, test_1_Norm, cl=train_sample,k=1)
predict

#The loan offer has been denied by the customer. It is determined when the k value=0

#Finding the best value of k

set.seed(350)
grid_1<-expand.grid(k=seq(1:30))                  
model_1<-train(Personal.Loan~.,data=train_1_Norm,method="knn",tuneGrid=grid_1)  

model_1

value_k<-model_1$bestTune[[1]]



#confusion matrix

predicted<-predict(model_1,valid_1_Norm[-9])
confusionMatrix(predicted,valid_sample)

#5 data is splitted to 50:30:20 ratio again

 set.seed(346) 
 
label_1<-createDataPartition(data_2$Personal.Loan,p=0.5,list=FALSE)
label_2<-createDataPartition(data_2$Personal.Loan,p=0.3,list=FALSE)
label_3<-createDataPartition(data_2$Personal.Loan,p=0.2,list=FALSE)

train_2<-data_2[label_1,]
valid_2<-data_2[label_2,]
test_2<-data_2[label_3,]
 
 
#normalizing new dataset

normal_1<-preProcess(train_1[,-(6:9)],method=c("center","scale"))

normalized_train_1 <- predict(normal_1,train_1)

normalized_valid_1<-predict(normal_1,valid_1)

normalized_test_1<-predict(normal_1,test_1)

#running knn for train,validation and test data

predict_new_train= normalized_train_1[,-9]

predict_new_train_1= normalized_train_1[,9]

predict_new_valid=normalized_valid_1[,-9]

predict_new_valid_1=normalized_valid_1[,9]

predict_new_test=normalized_test_1[,-9]

predict_new_test_1=normalized_test_1[,9]

View(predict_new_test_1)

Predict_train_new<-knn(predict_new_train,predict_new_train,cl=predict_new_train_1,k=value_k)

Predict_valid_new<-knn(predict_new_train,predict_new_valid,cl=predict_new_train_1,k=value_k)


#training ,validation and test data confusion matrix

confusionMatrix(Predict_train_new,predict_new_train_1)
confusionMatrix(Predict_valid_new,Predict_valid_new)


#CONCLUSION- We can conclude that the model performs well on the unseen data because the Test data has more accuracy, and greater sensitivity when compared to the Validation data.

```
